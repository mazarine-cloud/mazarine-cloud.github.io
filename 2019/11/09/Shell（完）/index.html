<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  <title>SHELL基础 - 阳光在心里</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_fmb4a04yx8h.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">




<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>时光蘑菇</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">
              <i class="iconfont icon-home-fill"></i>
              Home</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">
              <i class="iconfont icon-archive-fill"></i>
              Archives</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">
              <i class="iconfont icon-category-fill"></i>
              Categories</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">
              <i class="iconfont icon-tags-fill"></i>
              Tags</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">
              <i class="iconfont icon-user-fill"></i>
              About</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/links/">
              <i class="iconfont icon-link-fill"></i>
              Links</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2019-11-09 03:31">
                    November 9, 2019 am
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    5.2k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    49
                     分钟
                  </span>
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  <span id="busuanzi_container_page_pv" class="post-meta" style="display: none">
                    <i class="iconfont icon-eye" aria-hidden="true"></i>
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>
                
              </div>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p>大数据程序员为什么要学习Shell呢？<br>需要看懂运维人员编写的Shell程序。<br>偶尔会编写一些简单Shell程序来管理集群、提高开发效率。</p>
<a id="more"></a>
<h3 id="第1章-Shell概述"><a href="#第1章-Shell概述" class="headerlink" title="第1章 Shell概述"></a>第1章 Shell概述</h3><p>大数据程序员为什么要学习Shell呢？<br></p>
<ul>
<li>1）需要看懂运维人员编写的Shell程序。<br></li>
<li>2）偶尔会编写一些简单Shell程序来管理集群、提高开发效率。<br></li>
</ul>
<h3 id="第2章-Shell解析器"><a href="#第2章-Shell解析器" class="headerlink" title="第2章 Shell解析器"></a>第2章 Shell解析器<br></h3><h4 id="（1）Linux提供的Shell解析器有："><a href="#（1）Linux提供的Shell解析器有：" class="headerlink" title="（1）Linux提供的Shell解析器有："></a>（1）Linux提供的Shell解析器有：</h4><pre><code>[atguigu@hadoop101 ~]$ cat /etc/shells 
/bin/sh
/bin/bash
/sbin/nologin
/bin/dash
/bin/tcsh
/bin/csh</code></pre><h4 id="（2）bash和sh的关系"><a href="#（2）bash和sh的关系" class="headerlink" title="（2）bash和sh的关系"></a>（2）bash和sh的关系</h4><pre><code>[atguigu@hadoop101 bin]$ ll | grep bash
-rwxr-xr-x. 1 root root 941880 5月  11 2016 bash
lrwxrwxrwx. 1 root root  4 5月  27 2017 sh -&gt; bash</code></pre><h4 id="（3）Centos默认的解析器是bash"><a href="#（3）Centos默认的解析器是bash" class="headerlink" title="（3）Centos默认的解析器是bash"></a>（3）Centos默认的解析器是bash<br></h4><pre><code>[atguigu@hadoop102 bin]$ echo $SHELL
/bin/bash</code></pre><h3 id="第3章-Shell脚本入门"><a href="#第3章-Shell脚本入门" class="headerlink" title="第3章 Shell脚本入门"></a>第3章 Shell脚本入门</h3><h4 id="1．脚本格式"><a href="#1．脚本格式" class="headerlink" title="1．脚本格式 "></a>1．脚本格式 <br></h4><pre><code>脚本以#!/bin/bash开头（指定解析器）</code></pre><h4 id="2．第一个Shell脚本：helloworld"><a href="#2．第一个Shell脚本：helloworld" class="headerlink" title="2．第一个Shell脚本：helloworld "></a>2．第一个Shell脚本：helloworld <br></h4><h5 id="（1）需求：创建一个Shell脚本，输出helloworld"><a href="#（1）需求：创建一个Shell脚本，输出helloworld" class="headerlink" title="（1）需求：创建一个Shell脚本，输出helloworld "></a>（1）需求：创建一个Shell脚本，输出helloworld <br></h5><h5 id="（2）案例实操："><a href="#（2）案例实操：" class="headerlink" title="（2）案例实操： "></a>（2）案例实操： <br></h5><pre><code>[atguigu@hadoop101 datas]$ touch helloworld.sh 
[atguigu@hadoop101 datas]$ vi helloworld.sh 

在helloworld.sh中输入如下内容
#!/bin/bash
echo &quot;helloworld&quot;</code></pre><h5 id="（3）脚本的常用执行方式"><a href="#（3）脚本的常用执行方式" class="headerlink" title="（3）脚本的常用执行方式"></a>（3）脚本的常用执行方式<br></h5><ul>
<li>第一种：采用bash或sh+脚本的相对路径或绝对路径（不用赋予脚本+x权限）<br></li>
</ul>
<pre><code>sh+脚本的相对路径
[atguigu@hadoop101 datas]$ sh helloworld.sh 
Helloworld
sh+脚本的绝对路径
[atguigu@hadoop101 datas]$ sh /home/atguigu/datas/helloworld.sh 
helloworld
bash+脚本的相对路径
[atguigu@hadoop101 datas]$ bash helloworld.sh 
Helloworld
bash+脚本的绝对路径
[atguigu@hadoop101 datas]$ bash /home/atguigu/datas/helloworld.sh 
Helloworld</code></pre><ul>
<li>第二种：采用输入脚本的绝对路径或相对路径执行脚本（必须具有可执行权限+x）<br><br>（a）首先要赋予helloworld.sh 脚本的+x权限<br></li>
</ul>
<pre><code>[atguigu@hadoop101 datas]$ chmod 777 helloworld.sh&lt;br&gt;</code></pre><p>（b）执行脚本<br></p>
<pre><code>相对路径    
[atguigu@hadoop101 datas]$ ./helloworld.sh 
Helloworld
绝对路径
[atguigu@hadoop101 datas]$ /home/atguigu/datas/helloworld.sh 
Helloworld</code></pre><p>注意：第一种执行方法，本质是bash解析器帮你执行脚本，所以脚本本身不需要执行权限。<br><br>     第二种执行方法，本质是脚本需要自己执行，所以需要执行权限。<br></p>
<h4 id="3．第二个Shell脚本：多命令处理"><a href="#3．第二个Shell脚本：多命令处理" class="headerlink" title="3．第二个Shell脚本：多命令处理"></a>3．第二个Shell脚本：多命令处理<br></h4><h5 id="（1）需求："><a href="#（1）需求：" class="headerlink" title="（1）需求： "></a>（1）需求： <br></h5><pre><code>在/home/atguigu/目录下创建一个banzhang.txt,在banzhang.txt文件中增加“I love cls”。&lt;br&gt;</code></pre><h5 id="（2）案例实操：-1"><a href="#（2）案例实操：-1" class="headerlink" title="（2）案例实操："></a>（2）案例实操：</h5><pre><code>[atguigu@hadoop101 datas]$ touch batch.sh
[atguigu@hadoop101 datas]$ vi batch.sh

在batch.sh中输入如下内容
#!/bin/bash

cd /home/atguigu
touch cls.txt
echo &quot;I love cls&quot; &gt;&gt;cls.txt</code></pre><h3 id="第4章-Shell中的变量"><a href="#第4章-Shell中的变量" class="headerlink" title="第4章 Shell中的变量"></a>第4章 Shell中的变量<br></h3><h4 id="4-1-系统变量"><a href="#4-1-系统变量" class="headerlink" title="4.1 系统变量"></a>4.1 系统变量<br></h4><h5 id="1-常用系统变量"><a href="#1-常用系统变量" class="headerlink" title="1. 常用系统变量"></a>1. 常用系统变量<br></h5><pre><code>$HOME、$PWD、$SHELL、$USER等</code></pre><h5 id="2．案例实操"><a href="#2．案例实操" class="headerlink" title="2．案例实操"></a>2．案例实操<br></h5><h6 id="（1）查看系统变量的值"><a href="#（1）查看系统变量的值" class="headerlink" title="（1）查看系统变量的值"></a>（1）查看系统变量的值<br></h6><pre><code>[atguigu@hadoop101 datas]$ echo $HOME
/home/atguigu</code></pre><h6 id="（2）显示当前Shell中所有变量：set"><a href="#（2）显示当前Shell中所有变量：set" class="headerlink" title="（2）显示当前Shell中所有变量：set"></a>（2）显示当前Shell中所有变量：set<br></h6><pre><code>[atguigu@hadoop101 datas]$ set
BASH=/bin/bash
BASH_ALIASES=()
BASH_ARGC=()
BASH_ARGV=()</code></pre><h4 id="4-2-自定义变量"><a href="#4-2-自定义变量" class="headerlink" title="4.2 自定义变量"></a>4.2 自定义变量<br></h4><h5 id="1．基本语法"><a href="#1．基本语法" class="headerlink" title="1．基本语法"></a>1．基本语法<br></h5><pre><code>（1）定义变量：变量=值 &lt;br&gt;
（2）撤销变量：unset 变量&lt;br&gt;
（3）声明静态变量：readonly变量，注意：不能unset&lt;br&gt;</code></pre><h5 id="2．变量定义规则"><a href="#2．变量定义规则" class="headerlink" title="2．变量定义规则"></a>2．变量定义规则<br></h5><pre><code>（1）变量名称可以由字母、数字和下划线组成，但是不能以数字开头，环境变量名建议大写。
（2）等号两侧不能有空格
（3）在bash中，变量默认类型都是字符串类型，无法直接进行数值运算。
（4）变量的值如果有空格，需要使用双引号或单引号括起来。</code></pre><h5 id="3．案例实操"><a href="#3．案例实操" class="headerlink" title="3．案例实操"></a>3．案例实操<br></h5><h6 id="（1）定义变量A"><a href="#（1）定义变量A" class="headerlink" title="（1）定义变量A"></a>（1）定义变量A<br></h6><pre><code>[atguigu@hadoop101 datas]$ A=5
[atguigu@hadoop101 datas]$ echo $A
5</code></pre><h6 id="（2）给变量A重新赋值"><a href="#（2）给变量A重新赋值" class="headerlink" title="（2）给变量A重新赋值"></a>（2）给变量A重新赋值</h6><pre><code>[atguigu@hadoop101 datas]$ A=8
[atguigu@hadoop101 datas]$ echo $A
8</code></pre><h6 id="（3）撤销变量A"><a href="#（3）撤销变量A" class="headerlink" title="（3）撤销变量A"></a>（3）撤销变量A</h6><pre><code>[atguigu@hadoop101 datas]$ unset A
[atguigu@hadoop101 datas]$ echo $A</code></pre><h6 id="（4）声明静态的变量B-2，不能unset"><a href="#（4）声明静态的变量B-2，不能unset" class="headerlink" title="（4）声明静态的变量B=2，不能unset"></a>（4）声明静态的变量B=2，不能unset</h6><pre><code>[atguigu@hadoop101 datas]$ readonly B=2
[atguigu@hadoop101 datas]$ echo $B
2
[atguigu@hadoop101 datas]$ B=9
-bash: B: readonly variable</code></pre><h6 id="（5）在bash中，变量默认类型都是字符串类型，无法直接进行数值运算"><a href="#（5）在bash中，变量默认类型都是字符串类型，无法直接进行数值运算" class="headerlink" title="（5）在bash中，变量默认类型都是字符串类型，无法直接进行数值运算"></a>（5）在bash中，变量默认类型都是字符串类型，无法直接进行数值运算</h6><pre><code>[atguigu@hadoop102 ~]$ C=1+2
[atguigu@hadoop102 ~]$ echo $C
1+2</code></pre><h6 id="（6）变量的值如果有空格，需要使用双引号或单引号括起来"><a href="#（6）变量的值如果有空格，需要使用双引号或单引号括起来" class="headerlink" title="（6）变量的值如果有空格，需要使用双引号或单引号括起来"></a>（6）变量的值如果有空格，需要使用双引号或单引号括起来</h6><pre><code>[atguigu@hadoop102 ~]$ D=I love banzhang
-bash: world: command not found
[atguigu@hadoop102 ~]$ D=&quot;I love banzhang&quot;
[atguigu@hadoop102 ~]$ echo $A
I love banzhang</code></pre><h6 id="（7）可把变量提升为全局环境变量，可供其他Shell程序使用"><a href="#（7）可把变量提升为全局环境变量，可供其他Shell程序使用" class="headerlink" title="（7）可把变量提升为全局环境变量，可供其他Shell程序使用"></a>（7）可把变量提升为全局环境变量，可供其他Shell程序使用</h6><h4 id="export-变量名"><a href="#export-变量名" class="headerlink" title="export 变量名"></a>export 变量名</h4><pre><code>[atguigu@hadoop101 datas]$ vim helloworld.sh 

在helloworld.sh文件中增加echo $B
#!/bin/bash

echo &quot;helloworld&quot;
echo $B

[atguigu@hadoop101 datas]$ ./helloworld.sh 
Helloworld
发现并没有打印输出变量B的值。
[atguigu@hadoop101 datas]$ export B
[atguigu@hadoop101 datas]$ ./helloworld.sh 
helloworld
2</code></pre><h4 id="4-3-特殊变量：-n"><a href="#4-3-特殊变量：-n" class="headerlink" title="4.3 特殊变量：$n"></a>4.3 特殊变量：$n<br></h4><h5 id="1．基本语法-1"><a href="#1．基本语法-1" class="headerlink" title="1．基本语法"></a>1．基本语法<br></h5><pre><code>$n    （功能描述：n为数字，$0代表该脚本名称，$1-$9代表第一到第九个参数，十以上的参数，十以上的参数需要用大括号包含，如${10}）</code></pre><h5 id="2．案例实操-1"><a href="#2．案例实操-1" class="headerlink" title="2．案例实操"></a>2．案例实操<br></h5><h6 id="（1）输出该脚本文件名称、输入参数1和输入参数2-的值"><a href="#（1）输出该脚本文件名称、输入参数1和输入参数2-的值" class="headerlink" title="（1）输出该脚本文件名称、输入参数1和输入参数2 的值"></a>（1）输出该脚本文件名称、输入参数1和输入参数2 的值<br></h6><pre><code>[atguigu@hadoop101 datas]$ touch parameter.sh 
[atguigu@hadoop101 datas]$ vim parameter.sh
#!/bin/bash
echo &quot;$0  $1   $2&quot;

[atguigu@hadoop101 datas]$ chmod 777 parameter.sh

[atguigu@hadoop101 datas]$ ./parameter.sh cls  xz
./parameter.sh  cls   xz</code></pre><h4 id="4-4-特殊变量："><a href="#4-4-特殊变量：" class="headerlink" title="4.4 特殊变量：$#"></a>4.4 特殊变量：$#<br></h4><h5 id="1．基本语法-2"><a href="#1．基本语法-2" class="headerlink" title="1．基本语法"></a>1．基本语法</h5><pre><code>$#    （功能描述：获取所有输入参数个数，常用于循环）。</code></pre><h5 id="2．案例实操-2"><a href="#2．案例实操-2" class="headerlink" title="2．案例实操"></a>2．案例实操<br></h5><h6 id="（1）获取输入参数的个数"><a href="#（1）获取输入参数的个数" class="headerlink" title="（1）获取输入参数的个数"></a>（1）获取输入参数的个数</h6><pre><code>[atguigu@hadoop101 datas]$ vim parameter.sh

#!/bin/bash
echo &quot;$0  $1   $2&quot;
echo $#

[atguigu@hadoop101 datas]$ chmod 777 parameter.sh

[atguigu@hadoop101 datas]$ ./parameter.sh cls  xz
    parameter.sh cls xz 
    2</code></pre><h4 id="4-5-特殊变量：-、"><a href="#4-5-特殊变量：-、" class="headerlink" title="4.5 特殊变量：$*、$@"></a>4.5 特殊变量：$*、$@<br></h4><h5 id="1．基本语法-3"><a href="#1．基本语法-3" class="headerlink" title="1．基本语法"></a>1．基本语法<br></h5><pre><code>$*    （功能描述：这个变量代表命令行中所有的参数，$*把所有的参数看成一个整体）&lt;br&gt;
$@    （功能描述：这个变量也代表命令行中所有的参数，不过$@把每个参数区分对待）</code></pre><h5 id="2．案例实操-3"><a href="#2．案例实操-3" class="headerlink" title="2．案例实操"></a>2．案例实操</h5><h6 id="（1）打印输入的所有参数"><a href="#（1）打印输入的所有参数" class="headerlink" title="（1）打印输入的所有参数"></a>（1）打印输入的所有参数</h6><pre><code>[atguigu@hadoop101 datas]$ vim parameter.sh

#!/bin/bash
    echo &quot;$0  $1   $2&quot;
    echo $#
    echo $*
    echo $@

[atguigu@hadoop101 datas]$ bash parameter.sh 1 2 3
    parameter.sh  1   2
    3
    1 2 3
    1 2 3</code></pre><h4 id="4-6-特殊变量：-？"><a href="#4-6-特殊变量：-？" class="headerlink" title="4.6 特殊变量：$？"></a>4.6 特殊变量：$？<br></h4><h5 id="1．基本语法-4"><a href="#1．基本语法-4" class="headerlink" title="1．基本语法"></a>1．基本语法<br></h5><p>$？（功能描述：最后一次执行的命令的返回状态。如果这个变量的值为0，证明上一个命令正确执行；<br><br>如果这个变量的值为非0（具体是哪个数，由命令自己来决定），则证明上一个命令执行不正确了。）<br>#####2．案例实操<br></p>
<pre><code>（1）判断helloworld.sh脚本是否正确执行
[atguigu@hadoop101 datas]$ ./helloworld.sh 
hello world
[atguigu@hadoop101 datas]$ echo $?
0</code></pre><h3 id="第5章-运算符"><a href="#第5章-运算符" class="headerlink" title="第5章 运算符    "></a>第5章 运算符    <br></h3><h4 id="1．基本语法-5"><a href="#1．基本语法-5" class="headerlink" title="1．基本语法"></a>1．基本语法<br></h4><h5 id="（1）“-运算式-”或“-运算式-”"><a href="#（1）“-运算式-”或“-运算式-”" class="headerlink" title="（1）“$((运算式))”或“$[运算式]”"></a>（1）“$((运算式))”或“$[运算式]”<br></h5><h5 id="（2）expr-加，减，乘，除，取余"><a href="#（2）expr-加，减，乘，除，取余" class="headerlink" title="（2）expr  + , - , *,  /,  %    加，减，乘，除，取余"></a>（2）expr  + , - , *,  /,  %    加，减，乘，除，取余<br></h5><pre><code>注意：expr运算符间要有空格</code></pre><h4 id="2．案例实操："><a href="#2．案例实操：" class="headerlink" title="2．案例实操："></a>2．案例实操：</h4><h5 id="（1）计算3-2的值"><a href="#（1）计算3-2的值" class="headerlink" title="（1）计算3+2的值"></a>（1）计算3+2的值</h5><pre><code>[atguigu@hadoop101 datas]$ expr 2 + 3
5</code></pre><h5 id="（2）计算3-2的值"><a href="#（2）计算3-2的值" class="headerlink" title="（2）计算3-2的值"></a>（2）计算3-2的值</h5><pre><code>[atguigu@hadoop101 datas]$ expr 3 - 2 
1</code></pre><h5 id="（3）计算（2-3）X4的值"><a href="#（3）计算（2-3）X4的值" class="headerlink" title="（3）计算（2+3）X4的值"></a>（3）计算（2+3）X4的值</h5><pre><code>（a）expr一步完成计算
    [atguigu@hadoop101 datas]$ expr `expr 2 + 3` \* 4
    20
（b）采用$[运算式]方式
    [atguigu@hadoop101 datas]# S=$[(2+3)*4]
    [atguigu@hadoop101 datas]# echo $S</code></pre><h3 id="第6章-条件判断"><a href="#第6章-条件判断" class="headerlink" title="第6章 条件判断"></a>第6章 条件判断</h3><h4 id="1．基本语法-6"><a href="#1．基本语法-6" class="headerlink" title="1．基本语法"></a>1．基本语法</h4><pre><code>[ condition ]（注意condition前后要有空格）
注意：条件非空即为true，[ atguigu ]返回true，[] 返回false。</code></pre><h4 id="2-常用判断条件"><a href="#2-常用判断条件" class="headerlink" title="2. 常用判断条件"></a>2. 常用判断条件</h4><h5 id="（1）两个整数之间比较"><a href="#（1）两个整数之间比较" class="headerlink" title="（1）两个整数之间比较"></a>（1）两个整数之间比较</h5><pre><code>= 字符串比较
-lt 小于（less than）            -le 小于等于（less equal）
-eq 等于（equal）                -gt 大于（greater than）
-ge 大于等于（greater equal）    -ne 不等于（Not equal）</code></pre><h5 id="（2）按照文件权限进行判断"><a href="#（2）按照文件权限进行判断" class="headerlink" title="（2）按照文件权限进行判断"></a>（2）按照文件权限进行判断</h5><pre><code>-r 有读的权限（read）            -w 有写的权限（write）
-x 有执行的权限（execute）</code></pre><h5 id="（3）按照文件类型进行判断"><a href="#（3）按照文件类型进行判断" class="headerlink" title="（3）按照文件类型进行判断"></a>（3）按照文件类型进行判断</h5><pre><code>-f 文件存在并且是一个常规的文件（file）
-e 文件存在（existence）        -d 文件存在并是一个目录（directory）</code></pre><h4 id="3．案例实操-1"><a href="#3．案例实操-1" class="headerlink" title="3．案例实操"></a>3．案例实操</h4><h5 id="（1）23是否大于等于22"><a href="#（1）23是否大于等于22" class="headerlink" title="（1）23是否大于等于22"></a>（1）23是否大于等于22</h5><pre><code>[atguigu@hadoop101 datas]$ [ 23 -ge 22 ]
[atguigu@hadoop101 datas]$ echo $?
0</code></pre><h5 id="（2）helloworld-sh是否具有写权限"><a href="#（2）helloworld-sh是否具有写权限" class="headerlink" title="（2）helloworld.sh是否具有写权限"></a>（2）helloworld.sh是否具有写权限</h5><pre><code>[atguigu@hadoop101 datas]$ [ -w helloworld.sh ]
[atguigu@hadoop101 datas]$ echo $?
0</code></pre><h5 id="（3）-home-atguigu-cls-txt目录中的文件是否存在"><a href="#（3）-home-atguigu-cls-txt目录中的文件是否存在" class="headerlink" title="（3）/home/atguigu/cls.txt目录中的文件是否存在"></a>（3）/home/atguigu/cls.txt目录中的文件是否存在</h5><pre><code>[atguigu@hadoop101 datas]$ [ -e /home/b.txt ]
[atguigu@hadoop101 datas]$ echo $?
1</code></pre><h5 id="（4）多条件判断（-amp-amp-表示前一条命令执行成功时，才执行后一条命令，-表示上一条命令执行失败后，才执行下一条命令）"><a href="#（4）多条件判断（-amp-amp-表示前一条命令执行成功时，才执行后一条命令，-表示上一条命令执行失败后，才执行下一条命令）" class="headerlink" title="（4）多条件判断（&amp;&amp; 表示前一条命令执行成功时，才执行后一条命令，|| 表示上一条命令执行失败后，才执行下一条命令）"></a>（4）多条件判断（&amp;&amp; 表示前一条命令执行成功时，才执行后一条命令，|| 表示上一条命令执行失败后，才执行下一条命令）</h5><pre><code>[atguigu@hadoop101 ~]$ [ condition ] &amp;&amp; echo OK || echo notok
OK
[atguigu@hadoop101 datas]$ [ condition ] &amp;&amp; [ ] || echo notok
notok</code></pre><h3 id="第7章-流程控制（重点）"><a href="#第7章-流程控制（重点）" class="headerlink" title="第7章 流程控制（重点）"></a>第7章 流程控制（重点）</h3><h4 id="7-1-if-判断"><a href="#7-1-if-判断" class="headerlink" title="7.1 if 判断"></a>7.1 if 判断</h4><h5 id="1．基本语法-7"><a href="#1．基本语法-7" class="headerlink" title="1．基本语法"></a>1．基本语法</h5><pre><code>if [ 条件判断式 ];then 
  程序 
fi 
或者 
if [ 条件判断式 ] 
  then 
    程序 
fi</code></pre><p>注意事项：<br>（1）[ 条件判断式 ]，中括号和条件判断式之间必须有空格<br>（2）if后要有空格</p>
<h5 id="2．案例实操-4"><a href="#2．案例实操-4" class="headerlink" title="2．案例实操"></a>2．案例实操</h5><p>（1）输入一个数字，如果是1，则输出banzhang zhen shuai，如果是2，则输出cls zhen mei，如果是其它，什么也不输出。</p>
<pre><code>[atguigu@hadoop101 datas]$ touch if.sh
[atguigu@hadoop101 datas]$ vim if.sh

#!/bin/bash

if [ $1 -eq &quot;1&quot; ]
then
        echo &quot;banzhang zhen shuai&quot;
elif [ $1 -eq &quot;2&quot; ]
then
        echo &quot;cls zhen mei&quot;
fi

[atguigu@hadoop101 datas]$ chmod 777 if.sh 
[atguigu@hadoop101 datas]$ ./if.sh 1
banzhang zhen shuai</code></pre><h4 id="7-2-case-语句"><a href="#7-2-case-语句" class="headerlink" title="7.2 case 语句"></a>7.2 case 语句</h4><h5 id="1．基本语法-8"><a href="#1．基本语法-8" class="headerlink" title="1．基本语法"></a>1．基本语法</h5><pre><code>case $变量名 in 
  &quot;值1&quot;） 
    如果变量的值等于值1，则执行程序1 
    ;; 
  &quot;值2&quot;） 
    如果变量的值等于值2，则执行程序2 
    ;; 
  …省略其他分支… 
  *） 
    如果变量的值都不是以上的值，则执行此程序 
    ;; 
esac</code></pre><p>注意事项：</p>
<p>1)    case行尾必须为单词“in”，每一个模式匹配必须以右括号“）”结束。<br>2)    双分号“;;”表示命令序列结束，相当于java中的break。<br>3)    最后的“*）”表示默认模式，相当于java中的default。</p>
<h5 id="2．案例实操-5"><a href="#2．案例实操-5" class="headerlink" title="2．案例实操"></a>2．案例实操</h5><p>（1）输入一个数字，如果是1，则输出banzhang，如果是2，则输出cls，如果是其它，输出renyao。</p>
<pre><code>[atguigu@hadoop101 datas]$ touch case.sh
[atguigu@hadoop101 datas]$ vim case.sh

!/bin/bash

case $1 in
&quot;1&quot;)
        echo &quot;banzhang&quot;
;;

&quot;2&quot;)
        echo &quot;cls&quot;
;;
*)
        echo &quot;renyao&quot;
;;
esac

[atguigu@hadoop101 datas]$ chmod 777 case.sh
[atguigu@hadoop101 datas]$ ./case.sh 1
1</code></pre><h4 id="7-3-for-循环"><a href="#7-3-for-循环" class="headerlink" title="7.3 for 循环"></a>7.3 for 循环</h4><h5 id="1．基本语法1"><a href="#1．基本语法1" class="headerlink" title="1．基本语法1"></a>1．基本语法1</h5><pre><code>for (( 初始值;循环控制条件;变量变化 )) 
do 
  程序 
done</code></pre><h5 id="2．案例实操-6"><a href="#2．案例实操-6" class="headerlink" title="2．案例实操"></a>2．案例实操</h5><h6 id="（1）从1加到100"><a href="#（1）从1加到100" class="headerlink" title="（1）从1加到100"></a>（1）从1加到100</h6><pre><code>[atguigu@hadoop101 datas]$ touch for1.sh
[atguigu@hadoop101 datas]$ vim for1.sh

#!/bin/bash

s=0
for((i=0;i&lt;=100;i++))
do
        s=$[$s+$i]
done
echo $s

[atguigu@hadoop101 datas]$ chmod 777 for1.sh 
[atguigu@hadoop101 datas]$ ./for1.sh 
“5050”</code></pre><h5 id="3．基本语法2"><a href="#3．基本语法2" class="headerlink" title="3．基本语法2"></a>3．基本语法2</h5><pre><code>for 变量 in 值1 值2 值3… 
  do 
    程序 
  done</code></pre><h5 id="4．案例实操"><a href="#4．案例实操" class="headerlink" title="4．案例实操"></a>4．案例实操</h5><h6 id="（1）打印所有输入参数"><a href="#（1）打印所有输入参数" class="headerlink" title="（1）打印所有输入参数"></a>（1）打印所有输入参数</h6><pre><code>[atguigu@hadoop101 datas]$ touch for2.sh
[atguigu@hadoop101 datas]$ vim for2.sh

#!/bin/bash
#打印数字

for i in $*
    do
      echo &quot;ban zhang love $i &quot;
    done

[atguigu@hadoop101 datas]$ chmod 777 for2.sh 
[atguigu@hadoop101 datas]$ bash for2.sh cls xz bd
ban zhang love cls
ban zhang love xz
ban zhang love bd</code></pre><h6 id="（2）比较-和-区别"><a href="#（2）比较-和-区别" class="headerlink" title="（2）比较$*和$@区别"></a>（2）比较$*和$@区别</h6><p>（a）$*和$@都表示传递给函数或脚本的所有参数，不被双引号“”包含时，都以$1 $2 …$n的形式输出所有参数。</p>
<pre><code>[atguigu@hadoop101 datas]$ touch for.sh
[atguigu@hadoop101 datas]$ vim for.sh

#!/bin/bash 

for i in $*
do
      echo &quot;ban zhang love $i &quot;
done

for j in $@
do      
        echo &quot;ban zhang love $j&quot;
done

[atguigu@hadoop101 datas]$ bash for.sh cls xz bd
ban zhang love cls 
ban zhang love xz 
ban zhang love bd 
ban zhang love cls
ban zhang love xz
ban zhang love bd</code></pre><p>（b）当它们被双引号“”包含时，“$*”会将所有的参数作为一个整体，以“$1 $2 …$n”的形式输出所有参数；<br><br>“$@”会将各个参数分开，以“$1” “$2”…”$n”的形式输出所有参数。</p>
<pre><code>[atguigu@hadoop101 datas]$ vim for.sh

#!/bin/bash 

for i in &quot;$*&quot; 
#$*中的所有参数看成是一个整体，所以这个for循环只会循环一次 
        do 
                echo &quot;ban zhang love $i&quot;
        done 

for j in &quot;$@&quot; 
#$@中的每个参数都看成是独立的，所以“$@”中有几个参数，就会循环几次 
        do 
                echo &quot;ban zhang love $j&quot; 
done

[atguigu@hadoop101 datas]$ chmod 777 for.sh
[atguigu@hadoop101 datas]$ bash for.sh cls xz bd
ban zhang love cls xz bd
ban zhang love cls
ban zhang love xz
ban zhang love bd</code></pre><h4 id="7-4-while-循环"><a href="#7-4-while-循环" class="headerlink" title="7.4 while 循环"></a>7.4 while 循环</h4><h5 id="1．基本语法-9"><a href="#1．基本语法-9" class="headerlink" title="1．基本语法"></a>1．基本语法</h5><pre><code>while [ 条件判断式 ] 
  do 
    程序
  done</code></pre><h5 id="2．案例实操-7"><a href="#2．案例实操-7" class="headerlink" title="2．案例实操"></a>2．案例实操</h5><pre><code>（1）从1加到100

[atguigu@hadoop101 datas]$ touch while.sh
[atguigu@hadoop101 datas]$ vim while.sh

#!/bin/bash
s=0
i=1
while [ $i -le 100 ]
do
        s=$[$s+$i]
        i=$[$i+1]
done

echo $s

[atguigu@hadoop101 datas]$ chmod 777 while.sh 
[atguigu@hadoop101 datas]$ ./while.sh 
5050</code></pre><h3 id="第8章-read读取控制台输入"><a href="#第8章-read读取控制台输入" class="headerlink" title="第8章 read读取控制台输入"></a>第8章 read读取控制台输入</h3><h4 id="1．基本语法-10"><a href="#1．基本语法-10" class="headerlink" title="1．基本语法"></a>1．基本语法</h4><pre><code>    read(选项)(参数)
    选项：
-p：指定读取值时的提示符；
-t：指定读取值时等待的时间（秒）。
参数
    变量：指定读取值的变量名</code></pre><h4 id="2．案例实操-8"><a href="#2．案例实操-8" class="headerlink" title="2．案例实操"></a>2．案例实操</h4><h5 id="（1）提示7秒内，读取控制台输入的名称"><a href="#（1）提示7秒内，读取控制台输入的名称" class="headerlink" title="（1）提示7秒内，读取控制台输入的名称"></a>（1）提示7秒内，读取控制台输入的名称</h5><pre><code>[atguigu@hadoop101 datas]$ touch read.sh
[atguigu@hadoop101 datas]$ vim read.sh

#!/bin/bash

read -t 7 -p &quot;Enter your name in 7 seconds &quot; NAME
echo $NAME

[atguigu@hadoop101 datas]$ ./read.sh 
Enter your name in 7 seconds xiaoze
xiaoze</code></pre><h3 id="第9章-函数"><a href="#第9章-函数" class="headerlink" title="第9章 函数"></a>第9章 函数</h3><h4 id="9-1-系统函数"><a href="#9-1-系统函数" class="headerlink" title="9.1 系统函数"></a>9.1 系统函数</h4><h5 id="1．basename基本语法"><a href="#1．basename基本语法" class="headerlink" title="1．basename基本语法"></a>1．basename基本语法</h5><pre><code>basename [string / pathname] [suffix]      （功能描述：basename命令会删掉所有的前缀包括最后一个（‘/’）字符，然后将字符串显示出来。
选项：
suffix为后缀，如果suffix被指定了，basename会将pathname或string中的suffix去掉。</code></pre><h5 id="2．案例实操-9"><a href="#2．案例实操-9" class="headerlink" title="2．案例实操"></a>2．案例实操</h5><p>（1）截取该/home/atguigu/banzhang.txt路径的文件名称</p>
<pre><code>[atguigu@hadoop101 datas]$ basename /home/atguigu/banzhang.txt 
banzhang.txt
[atguigu@hadoop101 datas]$ basename /home/atguigu/banzhang.txt .txt
banzhang</code></pre><h5 id="3-dirname基本语法"><a href="#3-dirname基本语法" class="headerlink" title="3.    dirname基本语法"></a>3.    dirname基本语法</h5><pre><code>dirname 文件绝对路径（功能描述：从给定的包含绝对路径的文件名中去除文件名（非目录的部分），然后返回剩下的路径（目录的部分））</code></pre><h5 id="4．案例实操-1"><a href="#4．案例实操-1" class="headerlink" title="4．案例实操"></a>4．案例实操</h5><h6 id="（1）获取banzhang-txt文件的路径"><a href="#（1）获取banzhang-txt文件的路径" class="headerlink" title="（1）获取banzhang.txt文件的路径"></a>（1）获取banzhang.txt文件的路径</h6><pre><code>[atguigu@hadoop101 ~]$ dirname /home/atguigu/banzhang.txt 
/home/atguigu</code></pre><h4 id="9-2-自定义函数"><a href="#9-2-自定义函数" class="headerlink" title="9.2 自定义函数"></a>9.2 自定义函数</h4><h5 id="1．基本语法-11"><a href="#1．基本语法-11" class="headerlink" title="1．基本语法"></a>1．基本语法</h5><pre><code>[ function ] funname[()]
{
    Action;
    [return int;]
}
funname</code></pre><h5 id="2．经验技巧"><a href="#2．经验技巧" class="headerlink" title="2．经验技巧"></a>2．经验技巧</h5><pre><code>（1）必须在调用函数地方之前，先声明函数，shell脚本是逐行运行。不会像其它语言一样先编译。
（2）函数返回值，只能通过$?系统变量获得，可以显示加：return返回，如果不加，将以最后一条命令运行结果，作为返回值。return后跟数值n(0-255)</code></pre><h5 id="3．案例实操-2"><a href="#3．案例实操-2" class="headerlink" title="3．案例实操"></a>3．案例实操</h5><p>（1）计算两个输入参数的和</p>
<pre><code>[atguigu@hadoop101 datas]$ touch fun.sh
[atguigu@hadoop101 datas]$ vim fun.sh

#!/bin/bash
function sum()
{
    s=0
    s=$[ $1 + $2 ]
    echo &quot;$s&quot;
}

read -p &quot;Please input the number1: &quot; n1;
read -p &quot;Please input the number2: &quot; n2;
sum $n1 $n2;

[atguigu@hadoop101 datas]$ chmod 777 fun.sh
[atguigu@hadoop101 datas]$ ./fun.sh 
Please input the number1: 2
Please input the number2: 5
7</code></pre><h3 id="第10章-Shell工具（重点）"><a href="#第10章-Shell工具（重点）" class="headerlink" title="第10章 Shell工具（重点）"></a>第10章 Shell工具（重点）</h3><h4 id="10-1-cut"><a href="#10-1-cut" class="headerlink" title="10.1 cut"></a>10.1 cut</h4><p>cut的工作就是“剪”，具体的说就是在文件中负责剪切数据用的。cut 命令从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段输出。</p>
<h5 id="1-基本用法"><a href="#1-基本用法" class="headerlink" title="1.基本用法"></a>1.基本用法</h5><p>cut [选项参数]  filename<br>说明：默认分隔符是制表符</p>
<h5 id="2-选项参数说明"><a href="#2-选项参数说明" class="headerlink" title="2.选项参数说明"></a>2.选项参数说明</h5><p>表1-55<br>选项参数    功能<br>-f    列号，提取第几列<br>-d    分隔符，按照指定分隔符分割列</p>
<h5 id="3-案例实操"><a href="#3-案例实操" class="headerlink" title="3.案例实操"></a>3.案例实操</h5><h6 id="（0）数据准备"><a href="#（0）数据准备" class="headerlink" title="（0）数据准备"></a>（0）数据准备</h6><pre><code>[atguigu@hadoop101 datas]$ touch cut.txt
[atguigu@hadoop101 datas]$ vim cut.txt
dong shen
guan zhen
wo  wo
lai  lai
le  le</code></pre><h6 id="（1）切割cut-txt第一列"><a href="#（1）切割cut-txt第一列" class="headerlink" title="（1）切割cut.txt第一列"></a>（1）切割cut.txt第一列</h6><pre><code>[atguigu@hadoop101 datas]$ cut -d &quot; &quot; -f 1 cut.txt 
dong
guan
wo
lai
le</code></pre><h6 id="（2）切割cut-txt第二、三列"><a href="#（2）切割cut-txt第二、三列" class="headerlink" title="（2）切割cut.txt第二、三列"></a>（2）切割cut.txt第二、三列</h6><pre><code>[atguigu@hadoop101 datas]$ cut -d &quot; &quot; -f 2,3 cut.txt 
shen
zhen
 wo
 lai
 le</code></pre><h6 id="（3）在cut-txt文件中切割出guan"><a href="#（3）在cut-txt文件中切割出guan" class="headerlink" title="（3）在cut.txt文件中切割出guan"></a>（3）在cut.txt文件中切割出guan</h6><pre><code>[atguigu@hadoop101 datas]$ cat cut.txt | grep &quot;guan&quot; | cut -d &quot; &quot; -f 1
guan</code></pre><h6 id="（4）选取系统PATH变量值，第2个“：”开始后的所有路径："><a href="#（4）选取系统PATH变量值，第2个“：”开始后的所有路径：" class="headerlink" title="（4）选取系统PATH变量值，第2个“：”开始后的所有路径："></a>（4）选取系统PATH变量值，第2个“：”开始后的所有路径：</h6><pre><code>[atguigu@hadoop101 datas]$ echo $PATH
/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/atguigu/bin

[atguigu@hadoop102 datas]$ echo $PATH | cut -d: -f 2-
/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/atguigu/bin</code></pre><h6 id="（5）切割ifconfig-后打印的IP地址"><a href="#（5）切割ifconfig-后打印的IP地址" class="headerlink" title="（5）切割ifconfig 后打印的IP地址"></a>（5）切割ifconfig 后打印的IP地址</h6><pre><code>[atguigu@hadoop101 datas]$ ifconfig eth0 | grep &quot;inet addr&quot; | cut -d: -f 2 | cut -d&quot; &quot; -f1
192.168.1.102</code></pre><h4 id="10-2-sed"><a href="#10-2-sed" class="headerlink" title="10.2 sed"></a>10.2 sed</h4><p>sed是一种流编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”，接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重定向存储输出。</p>
<h5 id="1-基本用法-1"><a href="#1-基本用法-1" class="headerlink" title="1.    基本用法"></a>1.    基本用法</h5><p>sed [选项参数]  ‘command’  filename</p>
<h5 id="2-选项参数说明-1"><a href="#2-选项参数说明-1" class="headerlink" title="2.    选项参数说明"></a>2.    选项参数说明</h5><pre><code>表1-56
选项参数    功能
-e    直接在指令列模式上进行sed的动作编辑。</code></pre><h5 id="3-命令功能描述"><a href="#3-命令功能描述" class="headerlink" title="3.    命令功能描述"></a>3.    命令功能描述</h5><pre><code>表1-57
命令    功能描述
a     新增，a的后面可以接字串，在下一行出现
d    删除
s    查找并替换 
4.    案例实操</code></pre><h6 id="（0）数据准备-1"><a href="#（0）数据准备-1" class="headerlink" title="（0）数据准备"></a>（0）数据准备</h6><pre><code>[atguigu@hadoop102 datas]$ touch sed.txt
[atguigu@hadoop102 datas]$ vim sed.txt
dong shen
guan zhen
wo  wo
lai  lai

le  le</code></pre><h6 id="（1）将“mei-nv”这个单词插入到sed-txt第二行下，打印。"><a href="#（1）将“mei-nv”这个单词插入到sed-txt第二行下，打印。" class="headerlink" title="（1）将“mei nv”这个单词插入到sed.txt第二行下，打印。"></a>（1）将“mei nv”这个单词插入到sed.txt第二行下，打印。</h6><pre><code>[atguigu@hadoop102 datas]$ sed &apos;2a mei nv&apos; sed.txt 
dong shen
guan zhen
mei nv
wo  wo
lai  lai

le  le
[atguigu@hadoop102 datas]$ cat sed.txt 
dong shen
guan zhen
wo  wo
lai  lai

le  le
注意：文件并没有改变</code></pre><h6 id="（2）删除sed-txt文件所有包含wo的行"><a href="#（2）删除sed-txt文件所有包含wo的行" class="headerlink" title="（2）删除sed.txt文件所有包含wo的行"></a>（2）删除sed.txt文件所有包含wo的行</h6><pre><code>[atguigu@hadoop102 datas]$ sed &apos;/wo/d&apos; sed.txt
dong shen
guan zhen
lai  lai

le  le</code></pre><h6 id="（3）将sed-txt文件中wo替换为ni"><a href="#（3）将sed-txt文件中wo替换为ni" class="headerlink" title="（3）将sed.txt文件中wo替换为ni"></a>（3）将sed.txt文件中wo替换为ni</h6><pre><code>[atguigu@hadoop102 datas]$ sed &apos;s/wo/ni/g&apos; sed.txt 
dong shen
guan zhen
ni  ni
lai  lai

le  le
注意：‘g’表示global，全部替换</code></pre><h6 id="（4）将sed-txt文件中的第二行删除并将wo替换为ni"><a href="#（4）将sed-txt文件中的第二行删除并将wo替换为ni" class="headerlink" title="（4）将sed.txt文件中的第二行删除并将wo替换为ni"></a>（4）将sed.txt文件中的第二行删除并将wo替换为ni</h6><pre><code>[atguigu@hadoop102 datas]$ sed -e &apos;2d&apos; -e &apos;s/wo/ni/g&apos; sed.txt 
dong shen
ni  ni
lai  lai

le  le</code></pre><h4 id="10-3-awk"><a href="#10-3-awk" class="headerlink" title="10.3 awk"></a>10.3 awk</h4><p>一个强大的文本分析工具，把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行分析处理。</p>
<h5 id="1-基本用法-2"><a href="#1-基本用法-2" class="headerlink" title="1.    基本用法"></a>1.    基本用法</h5><pre><code>awk [选项参数] ‘pattern1{action1}  pattern2{action2}...’ filename
pattern：表示AWK在数据中查找的内容，就是匹配模式
action：在找到匹配内容时所执行的一系列命令</code></pre><h5 id="2-选项参数说明-2"><a href="#2-选项参数说明-2" class="headerlink" title="2.    选项参数说明"></a>2.    选项参数说明</h5><pre><code>表1-55
选项参数    功能
-F    指定输入文件折分隔符
-v    赋值一个用户定义变量</code></pre><h5 id="3-案例实操-1"><a href="#3-案例实操-1" class="headerlink" title="3.    案例实操"></a>3.    案例实操</h5><h6 id="（0）数据准备-2"><a href="#（0）数据准备-2" class="headerlink" title="（0）数据准备"></a>（0）数据准备</h6><pre><code>[atguigu@hadoop102 datas]$ sudo cp /etc/passwd ./</code></pre><h6 id="（1）搜索passwd文件以root关键字开头的所有行，并输出该行的第7列。"><a href="#（1）搜索passwd文件以root关键字开头的所有行，并输出该行的第7列。" class="headerlink" title="（1）搜索passwd文件以root关键字开头的所有行，并输出该行的第7列。"></a>（1）搜索passwd文件以root关键字开头的所有行，并输出该行的第7列。</h6><pre><code>[atguigu@hadoop102 datas]$ awk -F: &apos;/^root/{print $7}&apos; passwd 
/bin/bash</code></pre><h6 id="（2）搜索passwd文件以root关键字开头的所有行，并输出该行的第1列和第7列，中间以“，”号分割。"><a href="#（2）搜索passwd文件以root关键字开头的所有行，并输出该行的第1列和第7列，中间以“，”号分割。" class="headerlink" title="（2）搜索passwd文件以root关键字开头的所有行，并输出该行的第1列和第7列，中间以“，”号分割。"></a>（2）搜索passwd文件以root关键字开头的所有行，并输出该行的第1列和第7列，中间以“，”号分割。</h6><pre><code>[atguigu@hadoop102 datas]$ awk -F: &apos;/^root/{print $1&quot;,&quot;$7}&apos; passwd 
root,/bin/bash
注意：只有匹配了pattern的行才会执行action</code></pre><h6 id="（3）只显示-etc-passwd的第一列和第七列，以逗号分割，且在所有行前面添加列名user，shell在最后一行添加”dahaige，-bin-zuishuai”。"><a href="#（3）只显示-etc-passwd的第一列和第七列，以逗号分割，且在所有行前面添加列名user，shell在最后一行添加”dahaige，-bin-zuishuai”。" class="headerlink" title="（3）只显示/etc/passwd的第一列和第七列，以逗号分割，且在所有行前面添加列名user，shell在最后一行添加”dahaige，/bin/zuishuai”。"></a>（3）只显示/etc/passwd的第一列和第七列，以逗号分割，且在所有行前面添加列名user，shell在最后一行添加”dahaige，/bin/zuishuai”。</h6><pre><code>[atguigu@hadoop102 datas]$ awk -F : &apos;BEGIN{print &quot;user, shell&quot;} {print $1&quot;,&quot;$7} END{print &quot;dahaige,/bin/zuishuai&quot;}&apos; passwd
user, shell
root,/bin/bash
bin,/sbin/nologin
。。。
atguigu,/bin/bash
dahaige,/bin/zuishuai
注意：BEGIN 在所有数据读取行之前执行；END 在所有数据执行之后执行。</code></pre><h6 id="（4）将passwd文件中的用户id增加数值1并输出"><a href="#（4）将passwd文件中的用户id增加数值1并输出" class="headerlink" title="（4）将passwd文件中的用户id增加数值1并输出"></a>（4）将passwd文件中的用户id增加数值1并输出</h6><pre><code>[atguigu@hadoop102 datas]$ awk -v i=1 -F: &apos;{print $3+i}&apos; passwd
1
2
3
4</code></pre><h5 id="4-awk的内置变量"><a href="#4-awk的内置变量" class="headerlink" title="4.    awk的内置变量"></a>4.    awk的内置变量</h5><pre><code>表1-56
变量    说明
FILENAME    文件名
NR    已读的记录数
NF    浏览记录的域的个数（切割后，列的个数）</code></pre><h5 id="5-案例实操"><a href="#5-案例实操" class="headerlink" title="5.    案例实操"></a>5.    案例实操</h5><h6 id="（1）统计passwd文件名，每行的行号，每行的列数"><a href="#（1）统计passwd文件名，每行的行号，每行的列数" class="headerlink" title="（1）统计passwd文件名，每行的行号，每行的列数"></a>（1）统计passwd文件名，每行的行号，每行的列数</h6><pre><code>[atguigu@hadoop102 datas]$ awk -F: &apos;{print &quot;filename:&quot;  FILENAME &quot;, linenumber:&quot; NR  &quot;,columns:&quot; NF}&apos; passwd 
filename:passwd, linenumber:1,columns:7
filename:passwd, linenumber:2,columns:7
filename:passwd, linenumber:3,columns:7</code></pre><h6 id="（2）切割IP"><a href="#（2）切割IP" class="headerlink" title="（2）切割IP"></a>（2）切割IP</h6><pre><code>[atguigu@hadoop102 datas]$ ifconfig eth0 | grep &quot;inet addr&quot; | awk -F: &apos;{print $2}&apos; | awk -F &quot; &quot; &apos;{print $1}&apos; 
192.168.1.102</code></pre><h6 id="（3）查询sed-txt中空行所在的行号"><a href="#（3）查询sed-txt中空行所在的行号" class="headerlink" title="（3）查询sed.txt中空行所在的行号"></a>（3）查询sed.txt中空行所在的行号</h6><pre><code>[atguigu@hadoop102 datas]$ awk &apos;/^$/{print NR}&apos; sed.txt 
5</code></pre><h4 id="10-4-sort"><a href="#10-4-sort" class="headerlink" title="10.4 sort"></a>10.4 sort</h4><p>sort命令是在Linux里非常有用，它将文件进行排序，并将排序结果标准输出。</p>
<h5 id="1-基本语法"><a href="#1-基本语法" class="headerlink" title="1.    基本语法"></a>1.    基本语法</h5><pre><code>sort(选项)(参数)
表1-57
选项    说明
-n    依照数值的大小排序
-r    以相反的顺序来排序
-t    设置排序时所用的分隔字符
-k    指定需要排序的列
参数：指定待排序的文件列表</code></pre><h5 id="2-案例实操"><a href="#2-案例实操" class="headerlink" title="2. 案例实操"></a>2. 案例实操</h5><h6 id="（0）数据准备-3"><a href="#（0）数据准备-3" class="headerlink" title="（0）数据准备"></a>（0）数据准备</h6><pre><code>[atguigu@hadoop102 datas]$ touch sort.sh
[atguigu@hadoop102 datas]$ vim sort.sh 
bb:40:5.4
bd:20:4.2
xz:50:2.3
cls:10:3.5
ss:30:1.6</code></pre><h6 id="（1）按照“：”分割后的第三列倒序排序。"><a href="#（1）按照“：”分割后的第三列倒序排序。" class="headerlink" title="（1）按照“：”分割后的第三列倒序排序。"></a>（1）按照“：”分割后的第三列倒序排序。</h6><pre><code>[atguigu@hadoop102 datas]$ sort -t : -nrk 3  sort.sh 
bb:40:5.4
bd:20:4.2
cls:10:3.5
xz:50:2.3
ss:30:1.6</code></pre><h3 id="第11章-企业真实面试题（重点）"><a href="#第11章-企业真实面试题（重点）" class="headerlink" title="第11章 企业真实面试题（重点）"></a>第11章 企业真实面试题（重点）</h3><h4 id="11-1-京东"><a href="#11-1-京东" class="headerlink" title="11.1 京东"></a>11.1 京东</h4><h5 id="问题1：使用Linux命令查询file1中空行所在的行号"><a href="#问题1：使用Linux命令查询file1中空行所在的行号" class="headerlink" title="问题1：使用Linux命令查询file1中空行所在的行号"></a>问题1：使用Linux命令查询file1中空行所在的行号</h5><p>答案：</p>
<pre><code>[atguigu@hadoop102 datas]$ awk &apos;/^$/{print NR}&apos; sed.txt 
5</code></pre><p>问题2：有文件chengji.txt内容如下:</p>
<pre><code>张三 40
李四 50
王五 60</code></pre><p>使用Linux命令计算第二列的和并输出</p>
<pre><code>[atguigu@hadoop102 datas]$ cat chengji.txt | awk -F &quot; &quot; &apos;{sum+=$2} END{print sum}&apos;
150</code></pre><h4 id="11-2-搜狐-amp-和讯网"><a href="#11-2-搜狐-amp-和讯网" class="headerlink" title="11.2 搜狐&amp;和讯网"></a>11.2 搜狐&amp;和讯网</h4><p>问题1：Shell脚本里如何检查一个文件是否存在？如果不存在该如何处理？</p>
<pre><code>#!/bin/bash

if [ -f file.txt ]; then
   echo &quot;文件存在!&quot;
else
   echo &quot;文件不存在!&quot;
fi</code></pre><h4 id="11-3-新浪"><a href="#11-3-新浪" class="headerlink" title="11.3 新浪"></a>11.3 新浪</h4><p>问题1：用shell写一个脚本，对文本中无序的一列数字排序</p>
<pre><code>[root@CentOS6-2 ~]# cat test.txt
9
8
7
6
5
4
3
2
10
1
[root@CentOS6-2 ~]# sort -n test.txt|awk &apos;{a+=$0;print $0}END{print &quot;SUM=&quot;a}&apos;
1
2
3
4
5
6
7
8
9
10
SUM=55</code></pre><h4 id="11-3-金和网络"><a href="#11-3-金和网络" class="headerlink" title="11.3 金和网络"></a>11.3 金和网络</h4><p>问题1：请用shell脚本写出查找当前文件夹（/home）下所有的文本文件内容中包含有字符”shen”的文件名称</p>
<pre><code>[atguigu@hadoop102 datas]$ grep -r &quot;shen&quot; /home | cut -d &quot;:&quot; -f 1
/home/atguigu/datas/sed.txt
/home/atguigu/datas/cut.txt</code></pre><blockquote>
<p>声明：笔记采用自传智播客网络，共同学习共同进步。</p>
</blockquote>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/LINUX/">LINUX</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/linux/">linux</a>
                    
                      <a class="hover-with-bg" href="/tags/Shell/">Shell</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用CC BY-SA 3.0协议，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2019/12/07/%E5%9F%BA%E7%A1%80-%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8%E8%BF%AD%E4%BB%A3%E5%99%A8/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">为什么用迭代器(Iterator)</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2019/11/06/%E5%9F%BA%E7%A1%80-%E6%95%B0%E7%BB%84%E4%B8%8E%E9%93%BE%E8%A1%A8/">
                        <span class="hidden-mobile">字符串倒叙排列</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/mazarine-cloud/mazarine-cloud.github.io" target="_blank" rel="nofollow noopener">
        <span>时光蘑菇</span></a>
    </div>
    
  <div>
    
      <!-- 不蒜子统计PV -->
      
      <span id="busuanzi_container_site_pv" style="display: none">
      总访问量 418<span id="busuanzi_value_site_pv"></span> 次
    </span>
    
    
      <!-- 不蒜子统计UV -->
      
      <span id="busuanzi_container_site_uv" style="display: none">
      总访客数 45<span id="busuanzi_value_site_uv"></span> 人
    </span>
    
  </div>


    
  <!-- 备案信息 -->
  <div>
    <a href="http://beian.miit.gov.cn/" target="_blank" class="beian-icp"
       rel="nofollow noopener">京ICP证23743号</a>
    
      <a
        href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=679254"
        rel="nofollow noopener"
        class="beian-police"
        target="_blank"
      >
        <span class="beian-police-sep">&nbsp;|&nbsp;</span>
        
          <img src="/img/police_beian.png" srcset="/img/loading.gif" alt="police-icon" />
        
        <span>京公网安备12345678号</span>
      </a>
     
  </div>


    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 3,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "SHELL基础&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 200,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
      icon: "§"
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>







  
  
    <script>
      !function (e, t, a) {
        function r() {
          for (var e = 0; e < s.length; e++) s[e].alpha <= 0 ? (t.body.removeChild(s[e].el), s.splice(e, 1)) : (s[e].y--, s[e].scale += .004, s[e].alpha -= .013, s[e].el.style.cssText = "left:" + s[e].x + "px;top:" + s[e].y + "px;opacity:" + s[e].alpha + ";transform:scale(" + s[e].scale + "," + s[e].scale + ") rotate(45deg);background:" + s[e].color + ";z-index:99999");
          requestAnimationFrame(r)
        }

        function n() {
          var t = "function" == typeof e.onclick && e.onclick;
          e.onclick = function (e) {
            t && t(), o(e)
          }
        }

        function o(e) {
          var a = t.createElement("div");
          a.className = "heart", s.push({
            el: a,
            x: e.clientX - 5,
            y: e.clientY - 5,
            scale: 1,
            alpha: 1,
            color: c()
          }), t.body.appendChild(a)
        }

        function i(e) {
          var a = t.createElement("style");
          a.type = "text/css";
          try {
            a.appendChild(t.createTextNode(e))
          } catch (t) {
            a.styleSheet.cssText = e
          }
          t.getElementsByTagName("head")[0].appendChild(a)
        }

        function c() {
          return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
        }

        var s = [];
        e.requestAnimationFrame = e.requestAnimationFrame || e.webkitRequestAnimationFrame || e.mozRequestAnimationFrame || e.oRequestAnimationFrame || e.msRequestAnimationFrame || function (e) {
          setTimeout(e, 1e3 / 60)
        }, i(".heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}"), n(), r()
      }(window, document);
    </script>
  












</body>
</html>
